{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 应用场景\n",
    "- 单人（避免Speaker recognition）\n",
    "- 在说话 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_path = \"./demo.mp4\"\n",
    "api_key = \"\"\n",
    "concat_image = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#视觉模态\n",
    "#建议关键帧\n",
    "\n",
    "##默认ffmpeg,为了在端侧部署，我们选择最简单粗暴的方法。\n",
    "##先压缩到能部署上去，再考虑改进。\n",
    "\n",
    "def mp4_2_frames(mp4_path=\"./demo.mp4\", frames_output_dir=\"./frames_output_dir\") -> None:\n",
    "    \"\"\"\n",
    "    input:\n",
    "        mp4_path: str, mp4的路径\n",
    "        output_dir: str, 放你抽取的关键帧的文件夹, 用于后续对人脸面部表情进行识别\n",
    "    function:\n",
    "        根据视频，抽取关键帧并保存在frames_output_dir文件夹中，名字要有时间戳\n",
    "    output:\n",
    "        没有显示的输出，但是会在frames_output_dir文件夹中生成关键帧\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(frames_output_dir):\n",
    "        os.makedirs(frames_output_dir)\n",
    "    #用系统的ffmpeg库来处理，每15s抽取一帧\n",
    "    os.system(\"ffmpeg -i \"+mp4_path+\" -vf fps=1/15 \"+frames_output_dir+\"/%04d.jpg\")\n",
    "    return\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def video_modality(frames_dir, concat_image=False,concat_image_dir=\"./concat_image_dir\") -> None:\n",
    "    \"\"\"\n",
    "    input:\n",
    "        frames_dir: str, 存放关键帧的文件夹\n",
    "        concat_image_dir: str, 存放视频模态\n",
    "    function:\n",
    "        根据关键帧，提取视频模态并保存在modality_output_dir文件夹中\n",
    "    output:\n",
    "        str，一个格式化的对frames进行处理的输出\n",
    "        如果concat_image为True，那么还应该再concat_image_dir文件夹中生成视频模态\n",
    "    \"\"\"\n",
    "    \n",
    "    description = \"\"\n",
    "    #这个就自己写了\n",
    "    if concat_image==False:\n",
    "        pass\n",
    "        # to be done\n",
    "    else:\n",
    "        pass\n",
    "        # to be done\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmp4_2_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp4_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./frames_output_dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m, in \u001b[0;36mmp4_2_frames\u001b[0;34m(mp4_path, frames_output_dir)\u001b[0m\n\u001b[1;32m     19\u001b[0m stream \u001b[38;5;241m=\u001b[39m ffmpeg\u001b[38;5;241m.\u001b[39mfilter(stream, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfps\u001b[39m\u001b[38;5;124m'\u001b[39m, fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m     20\u001b[0m stream \u001b[38;5;241m=\u001b[39m ffmpeg\u001b[38;5;241m.\u001b[39moutput(stream, frames_output_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mffmpeg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ffmpeg/_run.py:313\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(stream_spec, cmd, capture_stdout, capture_stderr, input, quiet, overwrite_output)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;129m@output_operator\u001b[39m()\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    291\u001b[0m     stream_spec,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m     overwrite_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    298\u001b[0m ):\n\u001b[1;32m    299\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Invoke ffmpeg for the supplied node graph.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m    Returns: (out, err) tuple containing captured stdout and stderr data.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m     process \u001b[38;5;241m=\u001b[39m \u001b[43mrun_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipe_stdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipe_stdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_stdout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipe_stderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_stderr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     out, err \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    323\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ffmpeg/_run.py:284\u001b[0m, in \u001b[0;36mrun_async\u001b[0;34m(stream_spec, cmd, pipe_stdin, pipe_stdout, pipe_stderr, quiet, overwrite_output)\u001b[0m\n\u001b[1;32m    282\u001b[0m stdout_stream \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPIPE \u001b[38;5;28;01mif\u001b[39;00m pipe_stdout \u001b[38;5;129;01mor\u001b[39;00m quiet \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    283\u001b[0m stderr_stream \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPIPE \u001b[38;5;28;01mif\u001b[39;00m pipe_stderr \u001b[38;5;129;01mor\u001b[39;00m quiet \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstdin_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstdout_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstderr_stream\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/subprocess.py:966\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    963\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    964\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 966\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/subprocess.py:1842\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1841\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffmpeg'"
     ]
    }
   ],
   "source": [
    "mp4_2_frames(mp4_path, \"./frames_output_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 声音模态\n",
    "def mp4_2_wavs(mp4_path, wavs_output_dir) -> None:\n",
    "    \"\"\"\n",
    "    input:\n",
    "        mp4_path: str, mp4的路径\n",
    "        wavs_output_dir: str, 放你抽取的音频的文件夹\n",
    "    function:\n",
    "        根据视频，抽取音频并保存在wavs_output_dir文件夹中,也要带时间戳\n",
    "    output:\n",
    "        没有显示的输出，但是会在wavs_output_dir文件夹中生成音频文件wav\n",
    "        00:01-00:04.wav 00:05-00:08.wav等等\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def wav_modality(wav_dir,wav_emotion_txt = \"./wav_emotion.txt\"):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        wav_dir: str, mp4的路径\n",
    "        wav_output_dir: str, 放你抽取的音频的文件夹\n",
    "    function:\n",
    "        根据mp4，提取音频并转换成wav,再选择轻量级网络进行音频情感识别\n",
    "    output:\n",
    "        没有显示的输出，要求把音频情感识别的结果保存在wav_emotion_dir文件夹中相应的txt文件当中\n",
    "        wav_name: 00:01-00:04.wav wav_emotion: happy\n",
    "        ...\n",
    "    \"\"\"\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文字转录模态\n",
    "\n",
    "\n",
    "\n",
    "def text_modality(mp4_path, asr_txt=\"./asr_with_time_steps.txt\") -> str:\n",
    "    \"\"\"\n",
    "    input:\n",
    "        mp4_path: str, mp4的路径\n",
    "        api_key: str, 你的api_key\n",
    "    function:\n",
    "        根据mp4，提取音频并转换成文字\n",
    "    output:\n",
    "        str, 一个格式化的对转换后的文字的输出,能像whisper一样输出时间戳最好，这样可以尽量让多个模态稍稍对齐一点\n",
    "    \"\"\"\n",
    "    text_description = \"\"\n",
    "    return text_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_2_frames(mp4_path, \"./frames_output_dir\")\n",
    "video_modality(\"./frames_output_dir\", False, \"./concat_image_dir\")\n",
    "\n",
    "mp4_2_wavs(mp4_path, \"./wavs_output_dir\")\n",
    "wav_modality(\"./wavs_output_dir\", \"./wav_emotion.txt\")\n",
    "text_modality(mp4_path, \"./asr_with_time_steps.txt\")\n",
    "\n",
    "\n",
    "# 三个模态都处理完了，接下来就是把三个模态的结果拼接起来，然后输出到一个字符串中，为了良好的可读性，最好是按照时间戳来排列\n",
    "wav_and_text_info = [\n",
    "    {\n",
    "        \"time\": \"00:01-00:04\",\n",
    "        \"wav_emotion\": \"happy\",\n",
    "        \"asr_text\": \"hello, everyone\"\n",
    "    },\n",
    "    {\n",
    "        \n",
    "    },\n",
    "    # ...\n",
    "    {\n",
    "        \n",
    "    }\n",
    "]\n",
    "\n",
    "video_modality_info = [\n",
    "    {\n",
    "        \"time_stamp\": \"00:05\",\n",
    "        \"video_modality\": \"happy\"\n",
    "    },\n",
    "    {\n",
    "        \n",
    "    },\n",
    "    # ...\n",
    "    {\n",
    "        \n",
    "    }\n",
    "]\n",
    "\n",
    "info_text = f\"{wav_and_text_info}\\n\\n\\n{video_modality_info}\"\n",
    "prompt = \"你将会得到三个模态的分析结果，分别是视觉模态，声音模态和文字模态，其中视觉模态是对人脸面部表情的识别，声音模态是对音频情感的识别，文字模态是对音频的转录。我刻意用了时间戳来帮助你对齐这三个模态\\\n",
    "    请你综合这些信息，向我描述这个视频里说话人的情感变化状态和他/她的主要讲述内容，要求利用chain of thought的方式进行推理\"\n",
    "    \n",
    "# 或许可以写response \"并根据你的了解，作为一个能高情商的AI，你会如何回应这个视频里的说话人呢？\"\n",
    "\n",
    "# 或许可以想想其它prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大模型接入，总结，回应\n",
    "# 这里用deepseek的大模型来接入，然后输出一个总结，再回应用户"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TTS text to speech"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
